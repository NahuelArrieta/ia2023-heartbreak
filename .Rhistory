## get validation dataframe
test_dataframe <- get_test_df()
## preprocess the dataframe
preprocess_data <- preprocess(test_dataframe, train_variables)
test_dataframe <- preprocess_data$dataframe
message <- preprocess_data$message
## predict the test dataframe
test_dataframe$prediction_class <- predict(model, newdata = test_dataframe, type = "class")
## Set class as boolean
test_dataframe <- test_dataframe %>%
mutate(prediction_class = ifelse(prediction_class > 0.5, TRUE, FALSE))
## Calculate the metrics
FP <- sum(test_dataframe$prediction_class == TRUE & test_dataframe$is_fake == FALSE)
TP <- sum(test_dataframe$prediction_class == TRUE & test_dataframe$is_fake == TRUE)
FN <- sum(test_dataframe$prediction_class == FALSE & test_dataframe$is_fake == TRUE)
TN <- sum(test_dataframe$prediction_class == FALSE & test_dataframe$is_fake == FALSE)
## Calculate the metrics
accuracy <- (TP + TN) / (TP + TN + FP + FN)
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
specificity <- TN / (TN + FP)
negative_predictive_value <- TN / (TN + FN)
## Print the metrics
metrics <- "\nMetrics:"
metrics <- paste(metrics, "| | **Predicted Positive**| **Predicted Negative** | |")
metrics <- paste(metrics, "|:--:|:--:|:--:|:--:|")
metrics <- paste(metrics, "| **Actual Positive**", "| TP: ", TP, " | FN: ", FN, " | Sensitivity: ", recall, " |")
metrics <- paste(metrics, "| **Actual Negative**", "| FP: ", FP, " | TN: ", TN, " | Specificity: ", specificity, " |")
metrics <- paste(metrics, "| | Precision: ", precision, " | Negative Predictive Value: ", negative_predictive_value, " | **Accuracy**: ", accuracy, " |")
## Save the message and metrics
message_to_save <- paste(message, metrics)
file_name <- paste("results/", file_name, sep = "")
# Check if file already exists
if (file.exists(file_name)) {
# Find a new file name by appending a number
i <- 1
while (file.exists(paste0(file_name, ".", i))) {
i <- i + 1
}
file_name <- paste0(file_name, ".", i)
}
## Add sufix
file_name <- paste0(file_name, ".md")
write(message_to_save, file = file_name, append = FALSE, sep = "\n")
}
## test the model
test(model, train_variables, "test")
## test the model
test <- function(model, train_variables, file_name) {
## get validation dataframe
test_dataframe <- get_test_df()
## preprocess the dataframe
preprocess_data <- preprocess(test_dataframe, train_variables)
test_dataframe <- preprocess_data$dataframe
message <- preprocess_data$message
## predict the test dataframe
test_dataframe$prediction_class <- predict(model, newdata = test_dataframe, type = "class")
## Set class as boolean
test_dataframe <- test_dataframe %>%
mutate(prediction_class = ifelse(prediction_class > 0.5, TRUE, FALSE))
## Calculate the metrics
FP <- sum(test_dataframe$prediction_class == TRUE & test_dataframe$is_fake == FALSE)
TP <- sum(test_dataframe$prediction_class == TRUE & test_dataframe$is_fake == TRUE)
FN <- sum(test_dataframe$prediction_class == FALSE & test_dataframe$is_fake == TRUE)
TN <- sum(test_dataframe$prediction_class == FALSE & test_dataframe$is_fake == FALSE)
## Calculate the metrics
accuracy <- (TP + TN) / (TP + TN + FP + FN)
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
specificity <- TN / (TN + FP)
negative_predictive_value <- TN / (TN + FN)
## Print the metrics
metrics <- "\n ##Metrics:\n"
metrics <- paste(metrics, "| | **Predicted Positive**| **Predicted Negative** | |\n")
metrics <- paste(metrics, "|:--:|:--:|:--:|:--:|\n")
metrics <- paste(metrics, "| **Actual Positive**", "| TP: ", TP, " | FN: ", FN, " | Sensitivity: ", recall, " |\n")
metrics <- paste(metrics, "| **Actual Negative**", "| FP: ", FP, " | TN: ", TN, " | Specificity: ", specificity, " |\n")
metrics <- paste(metrics, "| | Precision: ", precision, " | Negative Predictive Value: ", negative_predictive_value, " | **Accuracy**: ", accuracy, " |\n")
## Save the message and metrics
title <- paste("# Test results for ", file_name, "\n")
message_to_save <- paste(title,message, metrics)
file_name <- paste("results/", file_name, sep = "")
# Check if file already exists
if (file.exists(file_name)) {
# Find a new file name by appending a number
i <- 1
while (file.exists(paste0(file_name, ".", i))) {
i <- i + 1
}
file_name <- paste0(file_name, ".", i)
}
## Add sufix
file_name <- paste0(file_name, ".md")
write(message_to_save, file = file_name, append = FALSE, sep = "\n")
}
## test the model
test(model, train_variables, "test")
## test the model
test <- function(model, train_variables, file_name) {
## get validation dataframe
test_dataframe <- get_test_df()
## preprocess the dataframe
preprocess_data <- preprocess(test_dataframe, train_variables)
test_dataframe <- preprocess_data$dataframe
message <- preprocess_data$message
## predict the test dataframe
test_dataframe$prediction_class <- predict(model, newdata = test_dataframe, type = "class")
## Set class as boolean
test_dataframe <- test_dataframe %>%
mutate(prediction_class = ifelse(prediction_class > 0.5, TRUE, FALSE))
## Calculate the metrics
FP <- sum(test_dataframe$prediction_class == TRUE & test_dataframe$is_fake == FALSE)
TP <- sum(test_dataframe$prediction_class == TRUE & test_dataframe$is_fake == TRUE)
FN <- sum(test_dataframe$prediction_class == FALSE & test_dataframe$is_fake == TRUE)
TN <- sum(test_dataframe$prediction_class == FALSE & test_dataframe$is_fake == FALSE)
## Calculate the metrics
accuracy <- (TP + TN) / (TP + TN + FP + FN)
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
specificity <- TN / (TN + FP)
negative_predictive_value <- TN / (TN + FN)
## Print the metrics
metrics <- "\n ## Metrics:\n"
metrics <- paste(metrics, "| | **Predicted Positive**| **Predicted Negative** | |\n")
metrics <- paste(metrics, "|:--:|:--:|:--:|:--:|\n")
metrics <- paste(metrics, "| **Actual Positive**", "| TP: ", TP, " | FN: ", FN, " | Sensitivity: ", recall, " |\n")
metrics <- paste(metrics, "| **Actual Negative**", "| FP: ", FP, " | TN: ", TN, " | Specificity: ", specificity, " |\n")
metrics <- paste(metrics, "| | Precision: ", precision, " | Negative Predictive Value: ", negative_predictive_value, " | **Accuracy**: ", accuracy, " |\n")
## Save the message and metrics
title <- paste("# Test results for ", file_name, "\n")
message_to_save <- paste(title,message, metrics)
file_name <- paste("results/", file_name, sep = "")
# Check if file already exists
if (file.exists(file_name)) {
# Find a new file name by appending a number
i <- 1
while (file.exists(paste0(file_name, ".", i))) {
i <- i + 1
}
file_name <- paste0(file_name, ".", i)
}
## Add sufix
file_name <- paste0(file_name, ".md")
write(message_to_save, file = file_name, append = FALSE, sep = "\n")
}
preprocess <- function(dataframe, train_variables) {
## Set class as boolean
dataframe$is_fake <- ifelse(dataframe$class == "f", TRUE, FALSE)
## Remove class column
dataframe <- dataframe[, -which(names(dataframe) == "class")]
## start message as empty
message <- "\n ## The following preprocessing steps will be applied: \n"
## Modify the dataframe according to the train variables
if (train_variables$remove_non_image_post_percentage) {
## Remove non image post percentage
message <- paste(message, "- Remove non image post percentage \n")
}
if (train_variables$remove_location_tag_percentage) {
## Remove location tag percentage
message <- paste(message, "- Remove location tag percentage \n")
}
if (train_variables$remove_comments_engagement_rate) {
## Remove comments engagement rate
message <- paste(message, "- Remove comments engagement rate \n")
}
if (train_variables$remove_caption_zero) {
## Remove caption zero
message <- paste(message, "- Remove caption zero \n")
}
if (train_variables$add_follow_difference) {
## Add follow difference
message <- paste(message, "- Add follow difference \n")
}
preprocess_data <- list(
dataframe = dataframe,
message = message
)
return(preprocess_data)
}
## train the model
model <- train_model(train_variables, ntree, mtry)
## test the model
test(model, train_variables, "test")
## Set file name
file_name <- "test"
preprocess <- function(dataframe, train_variables) {
## test the model
test(model, train_variables, file_name)
## test the model
test(model, train_variables, file_name)
preprocess <- function(dataframe, train_variables) {
## Set class as boolean
dataframe$is_fake <- ifelse(dataframe$class == "f", TRUE, FALSE)
## Remove class column
dataframe <- dataframe[, -which(names(dataframe) == "class")]
## start message as empty
message_title <- "\n ## The following preprocessing steps will be applied: \n"
message <- ""
## Modify the dataframe according to the train variables
if (train_variables$remove_non_image_post_percentage) {
## Remove non image post percentage
message <- paste(message, "- Remove non image post percentage \n")
}
if (train_variables$remove_location_tag_percentage) {
## Remove location tag percentage
message <- paste(message, "- Remove location tag percentage \n")
}
if (train_variables$remove_comments_engagement_rate) {
## Remove comments engagement rate
message <- paste(message, "- Remove comments engagement rate \n")
}
if (train_variables$remove_caption_zero) {
## Remove caption zero
message <- paste(message, "- Remove caption zero \n")
}
if (train_variables$add_follow_difference) {
## Add follow difference
message <- paste(message, "- Add follow difference \n")
}
if (message == "") {
message <- "No preprocessing steps will be applied"
}
message <- paste(message_title, message)
preprocess_data <- list(
dataframe = dataframe,
message = message
)
return(preprocess_data)
}
## test the model
test(model, train_variables, file_name)
## test the model
test <- function(model, train_variables, file_name) {
## get validation dataframe
test_dataframe <- get_test_df()
## preprocess the dataframe
preprocess_data <- preprocess(test_dataframe, train_variables)
test_dataframe <- preprocess_data$dataframe
message <- preprocess_data$message
## predict the test dataframe
test_dataframe$prediction_class <- predict(model, newdata = test_dataframe, type = "class")
## Set class as boolean
test_dataframe <- test_dataframe %>%
mutate(prediction_class = ifelse(prediction_class > 0.5, TRUE, FALSE))
## Calculate the metrics
FP <- sum(test_dataframe$prediction_class == TRUE & test_dataframe$is_fake == FALSE)
TP <- sum(test_dataframe$prediction_class == TRUE & test_dataframe$is_fake == TRUE)
FN <- sum(test_dataframe$prediction_class == FALSE & test_dataframe$is_fake == TRUE)
TN <- sum(test_dataframe$prediction_class == FALSE & test_dataframe$is_fake == FALSE)
## Calculate the metrics
accuracy <- (TP + TN) / (TP + TN + FP + FN)
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
specificity <- TN / (TN + FP)
negative_predictive_value <- TN / (TN + FN)
## Print the metrics
metrics <- "\n ## Metrics:\n"
metrics <- paste(metrics, "| | **Predicted Positive**| **Predicted Negative** | |\n")
metrics <- paste(metrics, "|:--:|:--:|:--:|:--:|\n")
metrics <- paste(metrics, "| **Actual Positive**", "| TP: ", TP, " | FN: ", FN, " | Sensitivity: ", recall, " |\n")
metrics <- paste(metrics, "| **Actual Negative**", "| FP: ", FP, " | TN: ", TN, " | Specificity: ", specificity, " |\n")
metrics <- paste(metrics, "| | Precision: ", precision, " | Negative Predictive Value: ", negative_predictive_value, " | **Accuracy**: ", accuracy, " |\n")
## Save the message and metrics
title <- paste("# Test results for ", file_name, "\n")
message_to_save <- paste(title,message, metrics)
file_name <- paste("results/", file_name, sep = "")
# Check if file already exists
if (file.exists(file_name)) {
# Find a new file name by appending a number
i <- 1
while (file.exists(paste0(file_name, ".", i))) {
i <- i + 1
}
file_name <- paste0(file_name, ".", i)
}
## Add sufix
file_name <- paste0(file_name, ".md")
write(message_to_save, file = file_name, append = FALSE, sep = "\n")
}
## test the model
test(model, train_variables, file_name)
## test the model
test(model, train_variables, "test")
## Get the dataframe
dataframe <- get_train_df()
## Preprocess the dataframe
preprocess_data <- preprocess(dataframe, train_variables)
dataframe <- preprocess_data$dataframe
## Train the model
model <- randomForest(
formula = is_fake ~ .,
data = dataframe,
ntree = ntree,
mtry = mtry
)
return(model)
train_model <- function(train_variables, ntree, mtry) {
## Get the dataframe
dataframe <- get_train_df()
## Preprocess the dataframe
preprocess_data <- preprocess(dataframe, train_variables)
dataframe <- preprocess_data$dataframe
## Train the model
model <- randomForest(
formula = is_fake ~ .,
data = dataframe,
ntree = ntree,
mtry = mtry
)
return(model)
}
## get validation dataframe
test_dataframe <- get_test_df()
## preprocess the dataframe
preprocess_data <- preprocess(test_dataframe, train_variables)
clear
## test the model
test <- function(model, train_variables, file_name) {
## get validation dataframe
test_dataframe <- get_test_df()
## preprocess the dataframe
preprocess_data <- preprocess(test_dataframe, train_variables)
test_dataframe <- preprocess_data$dataframe
message <- preprocess_data$message
## predict the test dataframe
test_dataframe$prediction_class <- predict(model, newdata = test_dataframe, type = "class")
## Set class as boolean
test_dataframe <- test_dataframe %>%
mutate(prediction_class = ifelse(prediction_class > 0.5, TRUE, FALSE))
## Calculate the metrics
FP <- sum(test_dataframe$prediction_class == TRUE & test_dataframe$is_fake == FALSE)
TP <- sum(test_dataframe$prediction_class == TRUE & test_dataframe$is_fake == TRUE)
FN <- sum(test_dataframe$prediction_class == FALSE & test_dataframe$is_fake == TRUE)
TN <- sum(test_dataframe$prediction_class == FALSE & test_dataframe$is_fake == FALSE)
## Calculate the metrics
accuracy <- (TP + TN) / (TP + TN + FP + FN)
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
specificity <- TN / (TN + FP)
negative_predictive_value <- TN / (TN + FN)
## Print the metrics
metrics <- "\n ## Metrics:\n"
metrics <- paste(metrics, "| | **Predicted Positive**| **Predicted Negative** | |\n")
metrics <- paste(metrics, "|:--:|:--:|:--:|:--:|\n")
metrics <- paste(metrics, "| **Actual Positive**", "| TP: ", TP, " | FN: ", FN, " | Sensitivity: ", recall, " |\n")
metrics <- paste(metrics, "| **Actual Negative**", "| FP: ", FP, " | TN: ", TN, " | Specificity: ", specificity, " |\n")
metrics <- paste(metrics, "| | Precision: ", precision, " | Negative Predictive Value: ", negative_predictive_value, " | **Accuracy**: ", accuracy, " |\n")
## Save the message and metrics
title <- paste("# Test results for ", file_name, "\n")
message_to_save <- paste(title,message, metrics)
file_name <- paste("results/", file_name, sep = "")
# Check if file already exists
if (file.exists(file_name)) {
# Find a new file name by appending a number
i <- 1
while (file.exists(paste0(file_name, ".", i))) {
i <- i + 1
}
file_name <- paste0(file_name, ".", i)
}
## Add sufix
file_name <- paste0(file_name, ".md")
write(message_to_save, file = file_name, append = FALSE, sep = "\n")
}
## test the model
test(model, train_variables, file_name)
preprocess <- function(dataframe, train_variables) {
## Set class as boolean
dataframe$is_fake <- ifelse(dataframe$class == "f", TRUE, FALSE)
## Remove class column
dataframe <- dataframe[, -which(names(dataframe) == "class")]
## start message as empty
message_title <- "\n ## The following preprocessing steps will be applied: \n"
message <- ""
## Modify the dataframe according to the train variables
if (train_variables$remove_non_image_post_percentage) {
## Remove non image post percentage
message <- paste(message, "- Remove non image post percentage \n")
}
if (train_variables$remove_location_tag_percentage) {
## Remove location tag percentage
message <- paste(message, "- Remove location tag percentage \n")
}
if (train_variables$remove_comments_engagement_rate) {
## Remove comments engagement rate
message <- paste(message, "- Remove comments engagement rate \n")
}
if (train_variables$remove_caption_zero) {
## Remove caption zero
message <- paste(message, "- Remove caption zero \n")
}
if (train_variables$add_follow_difference) {
## Add follow difference
message <- paste(message, "- Add follow difference \n")
}
if (message == "") {
message <- "No preprocessing steps will be applied"
}
message <- paste(message_title, message)
preprocess_data <- list(
dataframe = dataframe,
message = message
)
return(preprocess_data)
}
train_model <- function(train_variables, ntree, mtry) {
## Get the dataframe
dataframe <- get_train_df()
## Preprocess the dataframe
preprocess_data <- preprocess(dataframe, train_variables)
dataframe <- preprocess_data$dataframe
## Train the model
model <- randomForest(
formula = is_fake ~ .,
data = dataframe,
ntree = ntree,
mtry = mtry
)
return(model)
}
## test the model
test <- function(model, train_variables, file_name) {
## get validation dataframe
test_dataframe <- get_test_df()
## preprocess the dataframe
preprocess_data <- preprocess(test_dataframe, train_variables)
test_dataframe <- preprocess_data$dataframe
message <- preprocess_data$message
## predict the test dataframe
test_dataframe$prediction_class <- predict(model, newdata = test_dataframe, type = "class")
## Set class as boolean
test_dataframe <- test_dataframe %>%
mutate(prediction_class = ifelse(prediction_class > 0.5, TRUE, FALSE))
## Calculate the metrics
FP <- sum(test_dataframe$prediction_class == TRUE & test_dataframe$is_fake == FALSE)
TP <- sum(test_dataframe$prediction_class == TRUE & test_dataframe$is_fake == TRUE)
FN <- sum(test_dataframe$prediction_class == FALSE & test_dataframe$is_fake == TRUE)
TN <- sum(test_dataframe$prediction_class == FALSE & test_dataframe$is_fake == FALSE)
## Calculate the metrics
accuracy <- (TP + TN) / (TP + TN + FP + FN)
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
specificity <- TN / (TN + FP)
negative_predictive_value <- TN / (TN + FN)
## Print the metrics
metrics <- "\n ## Metrics:\n"
metrics <- paste(metrics, "| | **Predicted Positive**| **Predicted Negative** | |\n")
metrics <- paste(metrics, "|:--:|:--:|:--:|:--:|\n")
metrics <- paste(metrics, "| **Actual Positive**", "| TP: ", TP, " | FN: ", FN, " | Sensitivity: ", recall, " |\n")
metrics <- paste(metrics, "| **Actual Negative**", "| FP: ", FP, " | TN: ", TN, " | Specificity: ", specificity, " |\n")
metrics <- paste(metrics, "| | Precision: ", precision, " | Negative Predictive Value: ", negative_predictive_value, " | **Accuracy**: ", accuracy, " |\n")
## Save the message and metrics
title <- paste("# Test results for ", file_name, "\n")
message_to_save <- paste(title,message, metrics)
file_name <- paste("results/", file_name, sep = "")
# Check if file already exists
if (file.exists(file_name)) {
# Find a new file name by appending a number
i <- 1
while (file.exists(paste0(file_name, ".", i))) {
i <- i + 1
}
file_name <- paste0(file_name, ".", i)
}
## Add sufix
file_name <- paste0(file_name, ".md")
write(message_to_save, file = file_name, append = FALSE, sep = "\n")
}
source("~/Documents/Facultad/Inteligencia Artificial 1/final/code/get_dataset.R")
## create train_variables
train_variables <- list(
remove_non_image_post_percentage = FALSE,
remove_location_tag_percentage = FALSE,
remove_comments_engagement_rate = FALSE,
remove_caption_zero = FALSE,
add_follow_difference = FALSE
)
## Set number of trees
ntree <- 100
## Set number of variables
mtry <- 5
## Set file name
file_name <- "test"
## train the model
model <- train_model(train_variables, ntree, mtry)
## test the model
test(model, train_variables, file_name)
## train the model
model <- train_model(train_variables, ntree, mtry)
library(randomForest)
train_model <- function(train_variables, ntree, mtry) {
## Get the dataframe
dataframe <- get_train_df()
## Preprocess the dataframe
preprocess_data <- preprocess(dataframe, train_variables)
dataframe <- preprocess_data$dataframe
## Train the model
model <- randomForest(
formula = is_fake ~ .,
data = dataframe,
ntree = ntree,
mtry = mtry
)
return(model)
}
## train the model
model <- train_model(train_variables, ntree, mtry)
## test the model
test(model, train_variables, file_name)
source("~/Documents/Facultad/Inteligencia Artificial 1/final/code/test.R")
## test the model
test(model, train_variables, file_name)
